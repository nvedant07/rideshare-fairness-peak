{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, copy, os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt.base import matrix as m\n",
    "from cvxopt import solvers\n",
    "from cvxopt.modeling import op, dot, variable, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_unique_ids(objects):\n",
    "    for idx, obj in enumerate(objects):\n",
    "        obj.set_unique_id(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    def __init__(self, d_id, driver_race, driver_gender, pickup_lat_bin, pickup_long_bin, quota):\n",
    "        self.d_id = d_id\n",
    "        self.gender = driver_gender\n",
    "        self.race = driver_race\n",
    "        self.latitude = pickup_lat_bin\n",
    "        self.longitude = pickup_long_bin\n",
    "        self.quota = quota\n",
    "        self.is_present = True\n",
    "    \n",
    "    def set_unique_id(self, u_id):\n",
    "        # This is the unique ID used to index the edge matrix. \n",
    "        # To find the probability of a driver u accepting a ride of type v, see the entry mat[u.u_id][v.u_id]\n",
    "        self.u_id = u_id\n",
    "    \n",
    "    def __key(self):\n",
    "#         return (self.gender, self.race, self.latitude, self.longitude)\n",
    "        return (self.d_id)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__key())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Gender: {}, Race: {}, Lat bin: {}, Long bin: {}, Quota: {}\".format(self.gender, self.race,\n",
    "                                                                                  self.latitude, self.longitude,\n",
    "                                                                                  self.quota)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Driver):\n",
    "            return self.__key() == other.__key()\n",
    "        return NotImplemented\n",
    "\n",
    "class Request:\n",
    "    def __init__(self, pickup_lat_bin, pickup_long_bin, dropoff_lat_bin, dropoff_long_bin, \n",
    "                     requests_gender, requests_race, arrival_rate, distance):\n",
    "        self.gender = requests_gender\n",
    "        self.race = requests_race\n",
    "        self.start_latitude = pickup_lat_bin\n",
    "        self.start_longitude = pickup_long_bin\n",
    "        self.end_latitude = dropoff_lat_bin\n",
    "        self.end_longitude = dropoff_long_bin\n",
    "        self.arrival_rate = arrival_rate\n",
    "        self.distance = distance\n",
    "    \n",
    "    def set_unique_id(self, u_id):\n",
    "        # This is the unique ID used to index the edge matrix. \n",
    "        # To find the probability of a driver u accepting a ride of type v, see the entry mat[u.u_id][v.u_id]\n",
    "        self.u_id = u_id\n",
    "\n",
    "    def __key(self):\n",
    "        return (self.gender, self.race, self.start_latitude, self.start_longitude, \n",
    "                self.end_latitude, self.end_longitude)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__key())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Gender: {}, Race: {}, Start Lat bin: {}, Start Long bin: {}, End Lat bin: {}, End Long bin: {}\"\\\n",
    "                .format(self.gender, self.race, self.start_latitude, self.start_longitude, \n",
    "                                     self.end_latitude, self.end_longitude)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Request):\n",
    "            return self.__key() == other.__key()\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_to_index(i, j, probability_matrix):\n",
    "    \"\"\"Given a i,j in the probability matrix, convert to the index of the x_f vector\"\"\"\n",
    "    edges_count = np.count_nonzero(probability_matrix[:i,:] != -1) + np.count_nonzero(probability_matrix[i,:j] != -1)\n",
    "    # count the number of edges of drivers before i and  count the number of edges of ith driver before request j\n",
    "    return edges_count\n",
    "\n",
    "def index_to_coordinate(idx, probability_matrix):\n",
    "    return list(zip(*np.where(probability_matrix != -1)))[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_objective(x_fair, probability_matrix, requests):\n",
    "    # Minimize the negative of the objective function (same as maximizing the objective function)\n",
    "    all_requests_fairness = []\n",
    "    for j in range(probability_matrix.shape[1]):\n",
    "        mask = [0] * len(x_fair)\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "#             print (len(mask), coordinate_to_index(i, j, probability_matrix), i, j, probability_matrix.shape, len(requests))\n",
    "            mask[coordinate_to_index(i, j, probability_matrix)] = \\\n",
    "                -1 * (probability_matrix[i, j]/requests[j].arrival_rate)\n",
    "        all_requests_fairness.append(dot(m(mask), x_fair))\n",
    "    fairness = max(all_requests_fairness) # solver would minimize this\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_objective(x_f, probability_matrix, profit_matrix):\n",
    "    c = []\n",
    "    for i, j in zip(*np.where(probability_matrix != -1)):\n",
    "        c.append(-1 * profit_matrix[i,j] * probability_matrix[i,j]) # multiply by -1 since we want to maximise w_f * x_f * p_f but cvxopt minimizes the objective function by default, since minimizing -obj is same as maximizing obj, we multiply our profit objective by a minus sign\n",
    "    assert len(c) == len(x_f)\n",
    "    c = m(c)\n",
    "    profit = dot(c, x_f)\n",
    "    c, x_f\n",
    "    return profit, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inequalities(x, probability_matrix, requests, return_coefficients=False):\n",
    "    offset = 0\n",
    "    A, b = [], [] # model all inequalities as A * x <= b\n",
    "    # models the inequalities 3 and 4 in the writeup\n",
    "    for i in range(probability_matrix.shape[0]): # iterate over all drivers\n",
    "        a1, a2 = [0] * len(x), [0] * len(x) # coefficients of inequalities\n",
    "        edges_count = np.count_nonzero(probability_matrix[i] != -1)\n",
    "        edges_probabilities = probability_matrix[i][np.where(probability_matrix[i] != -1)]\n",
    "        assert len(edges_probabilities) == edges_count # sanity check\n",
    "        a1[offset:offset + edges_count] = edges_probabilities\n",
    "        a2[offset:offset + edges_count] = [1] * edges_count\n",
    "        A.append(a1)\n",
    "        A.append(a2)\n",
    "        b.append(1)\n",
    "        b.append(drivers[i].quota)\n",
    "        offset += edges_count\n",
    "    # Models the inequality -1 * x_f <= 0 for all edges\n",
    "    for i in range(len(x)):\n",
    "        a1 = [0] * len(x)\n",
    "        a1[i] = -1\n",
    "        A.append(a1)\n",
    "        b.append(0)\n",
    "    # Models inequality 5 in the writeup\n",
    "    for j in range(probability_matrix.shape[1]):# iterate over all request types\n",
    "        # j -> request; i-> driver\n",
    "        a1 = [0] * len(x)\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "            a1[coordinate_to_index(i, j, probability_matrix)] = 1\n",
    "        A.append(a1)\n",
    "        b.append(requests[j].arrival_rate)\n",
    "    print (len(A), len(b), len(A[0]), len(x))\n",
    "\n",
    "    A, b = m(A).T, m(b)\n",
    "\n",
    "    if not return_coefficients:\n",
    "        print (type(A*x))\n",
    "        inequality = (A * x <= b)\n",
    "        return inequality\n",
    "    else:\n",
    "        return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_solution_sanity_check(x_f, x_fair, probability_matrix, requests):\n",
    "    # Sanity Check: sum of all x_f for a request should be less than r_v\n",
    "    for j in range(probability_matrix.shape[1]):\n",
    "        sum_x_f = 0\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "            sum_x_f += x_f.value[coordinate_to_index(i, j, probability_matrix)]\n",
    "        if sum_x_f/requests[j].arrival_rate > 1:\n",
    "            assert np.isclose(sum_x_f/requests[j].arrival_rate, 1, atol=0.000001, rtol=0)\n",
    "    #     print (min(x_f.value/r.arrival_rate), max(x_f.value/r.arrival_rate))\n",
    "    #     print (min(x_fair.value/r.arrival_rate), max(x_fair.value/r.arrival_rate))\n",
    "    for i in range(len(x_f)):\n",
    "        if x_f.value[i] < 0:\n",
    "            assert np.isclose(x_f.value[i], 0, atol=0.000001, rtol=0)\n",
    "            x_f.value[i] = 0.0\n",
    "        if x_fair.value[i] < 0:\n",
    "            assert np.isclose(x_fair.value[i], 0, atol=0.000001, rtol=0)\n",
    "            x_fair.value[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_exact_fairness(all_requests, matching):\n",
    "    fairness_measure = []\n",
    "    requests = list(set(all_requests))\n",
    "    for r in requests:\n",
    "        fairness_measure.append(\n",
    "            np.count_nonzero(np.array(matching)[np.array(all_requests) == r] != None)/r.arrival_rate\n",
    "        )\n",
    "    fairness_measure = np.array(fairness_measure)\n",
    "    return np.min(fairness_measure[fairness_measure > 0]) if len(fairness_measure[fairness_measure > 0]) > 0 else 0\n",
    "\n",
    "def measure_fairness_edges_count(all_requests, matching, requests):\n",
    "    expected_edge_traversals = []\n",
    "    for r in requests: # note that requests here ensures that edge counts are ordered consistently\n",
    "        expected_edge_traversals.append(\n",
    "            np.count_nonzero(np.array(matching)[np.array(all_requests) == r] != None)\n",
    "        )\n",
    "    return np.array(expected_edge_traversals)\n",
    "    \n",
    "def measure_expected_fairness(r, x_f, y_f, alpha, beta, probability_matrix):\n",
    "    \"\"\"\n",
    "    r is a request type, x_f is the optimal profit assignment, y_f is the optimal fair assignment, \n",
    "    alpha is the weight to be given to profitable assignment and beta is the weight to be given to the fair assignment\n",
    "    \"\"\"\n",
    "    expectation = 0\n",
    "    for d in np.where(probability_matrix[:,r.u_id] != -1)[0]:\n",
    "        idx = coordinate_to_index(d, r.u_id, probability_matrix)\n",
    "        expectation += probability_matrix[d, r.u_id] * (alpha * x_f.value[idx] + beta * y_f.value[idx])\n",
    "    expectation /= r.arrival_rate\n",
    "    return expectation\n",
    "\n",
    "def measure_expected_profit(r, x_f, y_f, alpha, beta, probability_matrix):\n",
    "    \"\"\"\n",
    "    r is a request type, x_f is the optimal profit assignment, y_f is the optimal fair assignment, \n",
    "    alpha is the weight to be given to profitable assignment and beta is the weight to be given to the fair assignment\n",
    "    \"\"\"\n",
    "    expectation = 0\n",
    "    for d in np.where(probability_matrix[:,r.u_id] != -1)[0]:\n",
    "        idx = coordinate_to_index(d, r.u_id, probability_matrix)\n",
    "        expectation += probability_matrix[d, r.u_id] * (alpha * x_f.value[idx] + beta * y_f.value[idx]) * r.distance\n",
    "    return expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_acceptance(driver, request, probability_matrix):\n",
    "    p_f = probability_matrix[driver.u_id, request.u_id]\n",
    "#     print (\"Driver acceptance prob: {}, request: {}, is_present: {}\".format(p_f, request.u_id, driver.is_present))\n",
    "    if driver.is_present:\n",
    "        if driver.quota == 0: # Driver HAS to accept the request\n",
    "            driver.is_present = False\n",
    "            return driver\n",
    "        decision = np.random.choice(np.arange(2), size=1, p=[p_f, 1-p_f])[0]\n",
    "        if decision == 0: #driver accepted the trip\n",
    "#             print (\"Driver accepted request {}!\".format(request.u_id))\n",
    "            driver.is_present = False\n",
    "            return driver\n",
    "        else:\n",
    "            driver.quota -= 1\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def NAdap(alpha, beta, request, drivers_copy, probability_matrix, x_f, x_fair):\n",
    "    # There are 2 possible actions, choose assignment based on x_f* (profitable) and y_f* (fair) or reject\n",
    "    action = np.random.choice(np.arange(2), size=1, p=[alpha + beta, 1 - alpha - beta] if alpha + beta < 1 \\\n",
    "                              and alpha + beta > 0 else [int(alpha + beta), int(1 - alpha - beta)])[0]\n",
    "    if action == 0: # choose to assign\n",
    "        edge_coordinates, edge_indices, sample_probabilities_edge = [], [], []\n",
    "        for i in np.where(probability_matrix[:,request.u_id] != -1)[0]:\n",
    "            edge_coordinates.append((i, request.u_id))\n",
    "            idx = coordinate_to_index(i, request.u_id, probability_matrix)\n",
    "            edge_indices.append(idx)\n",
    "            sample_probabilities_edge.append(alpha * x_f.value[idx]/request.arrival_rate + \\\n",
    "                                         beta * x_fair.value[idx]/request.arrival_rate)\n",
    "#         print (\"Edges: {}, Sample edge probabilities: {}\".format(edge_coordinates, sample_probabilities_edge))\n",
    "        # difference between the sum of edge probs and 1\n",
    "        difference = 1 - np.sum(sample_probabilities_edge)\n",
    "        # scale up probabilities to ensure they add up to one\n",
    "        # only scale up the non-zero probabilities!!\n",
    "        if np.isclose(difference, 0, atol=0.000001, rtol=0):\n",
    "            sample_probabilities_edge[np.argmax(sample_probabilities_edge)] += difference\n",
    "        else:\n",
    "            indices_to_scale = np.where(np.array(sample_probabilities_edge) != 0)[0]\n",
    "            if len(indices_to_scale) == 0:\n",
    "                sample_probabilities_edge = \\\n",
    "                    [x + difference/len(sample_probabilities_edge) for x in sample_probabilities_edge]\n",
    "            else:\n",
    "#                 print (\"Here!\")\n",
    "                for idx in indices_to_scale:\n",
    "                    sample_probabilities_edge[idx] += difference/len(indices_to_scale)\n",
    "        try:\n",
    "            sampled_edge = np.random.choice(np.array(edge_indices), size=1, p=sample_probabilities_edge)[0]\n",
    "        except:\n",
    "            print (sample_probabilities_edge)\n",
    "        driver = drivers_copy[edge_coordinates[edge_indices.index(sampled_edge)][0]]\n",
    "        return driver_acceptance(driver, request, probability_matrix)\n",
    "    else: # reject the request\n",
    "        assert alpha + beta < 1, \"If alpha + beta == 1, this should not happen\"\n",
    "        return None\n",
    "\n",
    "def run_algorithm(all_requests, drivers_copy, probability_matrix, x_f, x_fair, alpha=0.5, beta=0.5):\n",
    "    exact_profit, count, available_drivers = 0, 0, count_available_drivers(drivers_copy)\n",
    "    assert available_drivers == len(drivers_copy)\n",
    "    matches = []\n",
    "    random.shuffle(all_requests)\n",
    "    for r in all_requests:\n",
    "        matched_driver = NAdap(alpha, beta, r, drivers_copy, probability_matrix, x_f, x_fair)\n",
    "        matches.append(matched_driver)\n",
    "        if matched_driver is not None:\n",
    "#             print (\"Driver found! : Driver: {}, Request: {}\".format(matched_driver.u_id, r.u_id))\n",
    "            available_drivers -= 1\n",
    "            assert available_drivers == count_available_drivers(drivers_copy)\n",
    "            exact_profit += r.distance\n",
    "            count += 1\n",
    "    return exact_profit, count, matches\n",
    "\n",
    "def count_available_drivers(drivers_copy):\n",
    "    count = 0\n",
    "    for d in drivers_copy:\n",
    "        if d.is_present:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_greedy(all_requests, drivers_copy, probability_matrix, profit_matrix):\n",
    "    matches, profit = [], 0\n",
    "    for request in all_requests:\n",
    "        available_drivers, profits = [], []\n",
    "        for idx in np.where(probability_matrix[:,request.u_id] != -1)[0]:\n",
    "            assert drivers_copy[idx].u_id == idx\n",
    "            if drivers_copy[idx].is_present:\n",
    "                available_drivers.append(drivers_copy[idx])\n",
    "                assert probability_matrix[idx, request.u_id] != -1\n",
    "                profits.append(profit_matrix[idx, request.u_id])\n",
    "        if len(available_drivers) == 0:\n",
    "            assigned_driver = None\n",
    "        else:\n",
    "            assigned_driver = driver_acceptance(available_drivers[np.argmax(profits)], \n",
    "                                                    request, probability_matrix)\n",
    "        matches.append(assigned_driver)\n",
    "        if assigned_driver is not None:\n",
    "            profit += request.distance\n",
    "    return matches, profit\n",
    "\n",
    "def run_uniform(all_requests, drivers_copy, probability_matrix):\n",
    "    matches, profit = [], 0\n",
    "    for r in all_requests:\n",
    "        driver_idx = np.random.choice(np.where(probability_matrix[:,r.u_id] != -1)[0], size=1)[0]\n",
    "        assert drivers_copy[driver_idx].u_id == driver_idx\n",
    "        assert probability_matrix[driver_idx, r.u_id] != -1\n",
    "        assigned_driver = driver_acceptance(drivers_copy[driver_idx], r, probability_matrix)\n",
    "        matches.append(assigned_driver)\n",
    "        if assigned_driver is not None:\n",
    "            profit += r.distance\n",
    "    return matches, profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_from_array(edges_count, num_loops, requests):\n",
    "    fairness_counts_all_runs = np.array(edges_count)\n",
    "#     error_counts = np.min(fairness_counts, axis=1) # will be used to calculate fairness for each run\n",
    "#     print (error_counts)\n",
    "#     error_args = np.argmin(fairness_counts, axis=1)\n",
    "#     assert len(error_counts) == num_loops and len(error_args) == num_loops\n",
    "#     for i in range(len(error_args)):\n",
    "#         error_counts[i] /= requests[error_args[i]].arrival_rate\n",
    "    fairness_counts = np.sum(fairness_counts_all_runs, axis=0)/num_loops\n",
    "    for idx in range(len(requests)):\n",
    "        fairness_counts[idx] /= requests[idx].arrival_rate\n",
    "    \n",
    "#     print(requests[np.argmin(fairness_counts)].arrival_rate)\n",
    "#     fairness_error = np.std(\n",
    "#         fairness_counts_all_runs[:,np.argmin(fairness_counts)] / \\\n",
    "#         requests[np.argmin(fairness_counts)].arrival_rate)\n",
    "#     print (fairness_error)\n",
    "    \n",
    "    return np.min(fairness_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_results(all_requests, drivers, probability_matrix, x_f, x_fair, alphas, num_loops):\n",
    "    algorithm_params = []\n",
    "    for alpha in alphas:\n",
    "        for i in range(num_loops):\n",
    "            algorithm_params.append([all_requests, [copy.deepcopy(d) for d in drivers], \n",
    "                                     probability_matrix, x_f, x_fair, alpha, 1-alpha])\n",
    "\n",
    "    with Pool(multiprocessing.cpu_count()) as p:\n",
    "        matching_results = p.starmap(run_algorithm, algorithm_params)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_count_results(all_requests, matching_results, requests):\n",
    "    fairness_measure_params = []\n",
    "    for matching_result in matching_results:\n",
    "        fairness_measure_params.append([all_requests, matching_result[2], requests])\n",
    "\n",
    "    with Pool(multiprocessing.cpu_count()) as p:\n",
    "        edges_count_results = p.starmap(measure_fairness_edges_count, fairness_measure_params)\n",
    "    return edges_count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_fairness_crs(matching_results, edges_count_results, num_loops, \n",
    "                            requests, alphas, optimal_profit, optimal_fairness):\n",
    "    profit_crs, profit_errors, fairness_crs, fairness_errors = [], [], [], []\n",
    "    for j in range(len(alphas)):\n",
    "        expected_profit, std_dev_profit = 0, []\n",
    "        for i in range(num_loops):\n",
    "            expected_profit += matching_results[j * num_loops + i][0]\n",
    "            std_dev_profit.append(matching_results[j * num_loops + i][0])\n",
    "        expected_profit /= num_loops\n",
    "        std_dev_profit = np.std(std_dev_profit)\n",
    "        profit_crs.append(expected_profit/optimal_profit)\n",
    "        profit_errors.append(std_dev_profit/optimal_profit)\n",
    "\n",
    "        fairness_measure = calculate_fairness_from_array(\n",
    "            edges_count_results[j*num_loops:(j+1)*num_loops], num_loops, requests)\n",
    "        print (expected_profit/optimal_profit, fairness_measure/optimal_fairness)\n",
    "        fairness_std_dev = 0\n",
    "        fairness_crs.append(fairness_measure/optimal_fairness)\n",
    "        fairness_errors.append(fairness_std_dev/optimal_fairness)\n",
    "    return profit_crs, profit_errors, fairness_crs, fairness_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_T(requests):\n",
    "    return np.sum([r.arrival_rate for r in requests])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
